{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d5daf10",
      "metadata": {
        "id": "5d5daf10"
      },
      "source": [
        "# ğŸ¬ YouTube è§†é¢‘è½¬å½•å·¥å…·\n",
        "\n",
        "å°† YouTube è§†é¢‘è½¬æ¢ä¸ºæ–‡å­—å’Œå­—å¹•æ–‡ä»¶ (txt + srt)\n",
        "\n",
        "**ä½¿ç”¨æ­¥éª¤ï¼š**\n",
        "1. ğŸ“ è¿è¡Œã€ŒæŒ‚è½½ Google Driveã€\n",
        "2. ğŸ“¦ è¿è¡Œã€Œå®‰è£…ä¾èµ–ã€\n",
        "3. âš™ï¸ å¡«å†™é…ç½®ï¼ˆYouTube URLã€æ¨¡å‹ç­‰ï¼‰\n",
        "4. ğŸš€ è¿è¡Œã€Œæ‰§è¡Œè½¬å½•ã€\n",
        "\n",
        "> âš ï¸ å¦‚é‡ 403 é”™è¯¯ï¼Œè¯·æŸ¥çœ‹åº•éƒ¨ã€Œå¸¸è§é—®é¢˜ã€éƒ¨åˆ†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d3f9df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70d3f9df",
        "outputId": "d847d010-a228-4af9-cc27-e1c0b3a2add2"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“ æŒ‚è½½ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# è®¾ç½®è¾“å‡ºç›®å½•\n",
        "import os\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/YouTubeTranscripts\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"âœ… è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
        "\n",
        "# æ£€æŸ¥ cookies æ–‡ä»¶\n",
        "COOKIES_PATH = \"/content/drive/MyDrive/cookies.txt\"\n",
        "if os.path.exists(COOKIES_PATH):\n",
        "    print(f\"ğŸª å‘ç° cookies æ–‡ä»¶: {COOKIES_PATH}\")\n",
        "else:\n",
        "    print(\"â„¹ï¸ æœªå‘ç° cookies.txtï¼Œå¦‚é‡ 403 é”™è¯¯è¯·å‚è€ƒè¯´æ˜ä¸Šä¼ \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5114a837",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5114a837",
        "outputId": "375958fb-45ef-4274-96d5-337347f32fbc"
      },
      "outputs": [],
      "source": [
        "#@title ğŸ“¦ å®‰è£…ä¾èµ– (è‡ªåŠ¨æ£€æŸ¥ï¼Œå·²å®‰è£…åˆ™è·³è¿‡)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def check_and_install(package_name, import_name=None):\n",
        "    \"\"\"æ£€æŸ¥åŒ…æ˜¯å¦å·²å®‰è£…ï¼Œæœªå®‰è£…åˆ™å®‰è£…\"\"\"\n",
        "    import_name = import_name or package_name\n",
        "    try:\n",
        "        __import__(import_name)\n",
        "        print(f\"âœ… {package_name} å·²å®‰è£…\")\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(f\"ğŸ“¦ æ­£åœ¨å®‰è£… {package_name}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n",
        "        print(f\"âœ… {package_name} å®‰è£…å®Œæˆ\")\n",
        "        return False\n",
        "\n",
        "# å®‰è£… Deno JavaScript è¿è¡Œæ—¶ (yt-dlp 2025+ å¿…éœ€)\n",
        "print(\"ğŸ“¦ æ£€æŸ¥/å®‰è£… Deno JavaScript è¿è¡Œæ—¶...\")\n",
        "deno_path = os.path.expanduser(\"~/.deno/bin/deno\")\n",
        "if not os.path.exists(deno_path):\n",
        "    subprocess.run(\"curl -fsSL https://deno.land/install.sh | sh\", shell=True, check=True)\n",
        "    print(\"âœ… Deno å®‰è£…å®Œæˆ\")\n",
        "else:\n",
        "    print(\"âœ… Deno å·²å®‰è£…\")\n",
        "\n",
        "# æ·»åŠ  Deno åˆ° PATH\n",
        "os.environ[\"PATH\"] = os.path.expanduser(\"~/.deno/bin\") + os.pathsep + os.environ.get(\"PATH\", \"\")\n",
        "\n",
        "# å¼ºåˆ¶æ›´æ–° yt-dlp åˆ°æœ€æ–°ç‰ˆæœ¬ (è§£å†³ 403 é—®é¢˜çš„å…³é”®)\n",
        "print(\"ğŸ“¦ æ›´æ–° yt-dlp åˆ°æœ€æ–°ç‰ˆæœ¬...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"yt-dlp\"])\n",
        "print(\"âœ… yt-dlp å·²æ›´æ–°\")\n",
        "\n",
        "# æ£€æŸ¥å¹¶å®‰è£… whisper\n",
        "check_and_install(\"openai-whisper\", \"whisper\")\n",
        "\n",
        "print(\"\\nâœ… æ‰€æœ‰ä¾èµ–å°±ç»ªï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff06d9e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff06d9e9",
        "outputId": "d7fe2fea-c4ba-432a-b099-20a24503fbe7"
      },
      "outputs": [],
      "source": [
        "#@title âš™ï¸ é…ç½®\n",
        "\n",
        "#@markdown ### YouTube è§†é¢‘ URL\n",
        "#@markdown å¤šä¸ª URL ç”¨ **ç«–çº¿ `|`** åˆ†éš”ï¼Œä¾‹å¦‚: `URL1 | URL2 | URL3`\n",
        "YOUTUBE_URLS = \"https://youtu.be/xxxxxxxxxx\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### å¯é€‰è®¾ç½®\n",
        "MODEL = \"large-v3\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\"]\n",
        "LANGUAGE = \"\" #@param {type:\"string\"}\n",
        "#@markdown ç•™ç©ºè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼Œæˆ–æŒ‡å®šè¯­è¨€ä»£ç å¦‚: `zh`, `en`, `ja`\n",
        "\n",
        "#@markdown ### 403 é”™è¯¯ä¿®å¤\n",
        "USE_COOKIES = False #@param {type:\"boolean\"}\n",
        "#@markdown å¯ç”¨åå°†ä½¿ç”¨ Google Drive æ ¹ç›®å½•çš„ cookies.txt\n",
        "\n",
        "# è§£æ URL åˆ—è¡¨ï¼ˆæ”¯æŒç«–çº¿ | åˆ†éš”ï¼‰\n",
        "import re\n",
        "url_list = [u.strip() for u in YOUTUBE_URLS.split('|') if u.strip()]\n",
        "\n",
        "print(f\"ğŸ¬ å¾…å¤„ç†è§†é¢‘æ•°é‡: {len(url_list)}\")\n",
        "for i, url in enumerate(url_list, 1):\n",
        "    print(f\"   {i}. {url}\")\n",
        "print(f\"ğŸ¤– æ¨¡å‹: {MODEL}\")\n",
        "print(f\"ğŸŒ è¯­è¨€: {LANGUAGE if LANGUAGE else 'è‡ªåŠ¨æ£€æµ‹'}\")\n",
        "print(f\"ğŸª ä½¿ç”¨ Cookies: {'æ˜¯' if USE_COOKIES else 'å¦'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db323dab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "db323dab",
        "outputId": "db1dc007-28c5-46c1-d2d6-8df284807713"
      },
      "outputs": [],
      "source": [
        "#@title ğŸš€ æ‰§è¡Œè½¬å½•ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰\n",
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import tempfile\n",
        "import time\n",
        "import importlib.util\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import whisper\n",
        "\n",
        "# ===== å·¥å…·å‡½æ•° =====\n",
        "\n",
        "def parse_youtube_url(url: str) -> str | None:\n",
        "    \"\"\"è§£æ YouTube URLï¼Œæå– video_id\"\"\"\n",
        "    patterns = [\n",
        "        r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=([a-zA-Z0-9_-]{11})',\n",
        "        r'(?:https?://)?(?:www\\.)?youtube\\.com/embed/([a-zA-Z0-9_-]{11})',\n",
        "        r'(?:https?://)?(?:www\\.)?youtube\\.com/v/([a-zA-Z0-9_-]{11})',\n",
        "        r'(?:https?://)?youtu\\.be/([a-zA-Z0-9_-]{11})',\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, url)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "    return None\n",
        "\n",
        "\n",
        "def sanitize_filename(filename: str, max_bytes: int = 180) -> str:\n",
        "    \"\"\"æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦ï¼Œå¹¶é™åˆ¶å­—èŠ‚é•¿åº¦ï¼ˆå…¼å®¹ä¸­æ–‡ï¼‰\"\"\"\n",
        "    illegal_chars = r'[<>:\"/\\\\|?*]'\n",
        "    sanitized = re.sub(illegal_chars, '_', filename)\n",
        "    # æŒ‰å­—èŠ‚é•¿åº¦æˆªæ–­ï¼ˆUTF-8 ä¸­æ–‡å  3 å­—èŠ‚ï¼Œç•™ä½™é‡ç»™æ‰©å±•åï¼‰\n",
        "    encoded = sanitized.encode('utf-8')\n",
        "    if len(encoded) > max_bytes:\n",
        "        result = ''\n",
        "        current_bytes = 0\n",
        "        for char in sanitized:\n",
        "            char_bytes = len(char.encode('utf-8'))\n",
        "            if current_bytes + char_bytes > max_bytes:\n",
        "                break\n",
        "            result += char\n",
        "            current_bytes += char_bytes\n",
        "        return result\n",
        "    return sanitized\n",
        "\n",
        "\n",
        "def format_timestamp(seconds: float) -> str:\n",
        "    \"\"\"å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æˆ³æ ¼å¼ (HH:MM:SS,mmm)\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    millis = int((seconds % 1) * 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
        "\n",
        "\n",
        "def format_duration(seconds: float) -> str:\n",
        "    \"\"\"å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºå¯è¯»æ—¶é•¿\"\"\"\n",
        "    if seconds < 60:\n",
        "        return f\"{seconds:.1f}ç§’\"\n",
        "    elif seconds < 3600:\n",
        "        mins = int(seconds // 60)\n",
        "        secs = int(seconds % 60)\n",
        "        return f\"{mins}åˆ†{secs}ç§’\"\n",
        "    else:\n",
        "        hours = int(seconds // 3600)\n",
        "        mins = int((seconds % 3600) // 60)\n",
        "        return f\"{hours}å°æ—¶{mins}åˆ†\"\n",
        "\n",
        "\n",
        "def detect_js_runtime() -> dict | None:\n",
        "    \"\"\"è‡ªåŠ¨æ£€æµ‹å¯ç”¨ JS runtime\"\"\"\n",
        "    runtime_bins = {\n",
        "        \"deno\": [\"deno\"],\n",
        "        \"bun\": [\"bun\"],\n",
        "        \"node\": [\"node\"],\n",
        "        \"quickjs\": [\"qjs\", \"quickjs\"],\n",
        "    }\n",
        "    for name, bins in runtime_bins.items():\n",
        "        for bin_name in bins:\n",
        "            path = shutil.which(bin_name)\n",
        "            if path:\n",
        "                return {name: {\"path\": path}}\n",
        "    return None\n",
        "\n",
        "\n",
        "def find_cookie_file(search_dir: Path) -> Path | None:\n",
        "    \"\"\"åœ¨æŒ‡å®šç›®å½•ä¸­æŸ¥æ‰¾ cookies æ–‡ä»¶\"\"\"\n",
        "    if not search_dir.exists():\n",
        "        return None\n",
        "    preferred = search_dir / \"cookies.txt\"\n",
        "    if preferred.exists():\n",
        "        return preferred\n",
        "    candidates = list(search_dir.glob(\"*.txt\"))\n",
        "    if not candidates:\n",
        "        return None\n",
        "    candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "    return candidates[0]\n",
        "\n",
        "\n",
        "def preflight_check(cookies_path: str | None, js_runtimes: dict | None) -> None:\n",
        "    \"\"\"æ‰§è¡Œç¯å¢ƒè‡ªæ£€å¹¶è¾“å‡ºæç¤º\"\"\"\n",
        "    print(\"ğŸ” ç¯å¢ƒè‡ªæ£€...\")\n",
        "\n",
        "    # yt-dlp ç‰ˆæœ¬\n",
        "    try:\n",
        "        from yt_dlp import version as ydl_version\n",
        "        print(f\"   yt-dlp: {ydl_version.__version__}\")\n",
        "    except Exception:\n",
        "        print(\"   yt-dlp: unknown\")\n",
        "\n",
        "    # JS runtime\n",
        "    if js_runtimes:\n",
        "        print(f\"   JS runtime: {', '.join(js_runtimes.keys())}\")\n",
        "    else:\n",
        "        print(\"   JS runtime: æœªæ£€æµ‹åˆ°\")\n",
        "        print(\"     âš ï¸ å»ºè®®å®‰è£… Deno (è¿è¡Œä¸Šæ–¹çš„å®‰è£…ä¾èµ–å•å…ƒæ ¼)\")\n",
        "\n",
        "    # EJS ç»„ä»¶æ£€æµ‹\n",
        "    ejs_local = False\n",
        "    if importlib.util.find_spec(\"yt_dlp_ejs\") is not None:\n",
        "        ejs_local = True\n",
        "    elif importlib.util.find_spec(\"ytdlp_ejs\") is not None:\n",
        "        ejs_local = True\n",
        "\n",
        "    if ejs_local:\n",
        "        print(\"   EJS: å·²å®‰è£… (yt-dlp-ejs)\")\n",
        "    else:\n",
        "        print(\"   EJS: æœªæ£€æµ‹åˆ° (éƒ¨åˆ†è§†é¢‘å¯èƒ½éœ€è¦)\")\n",
        "\n",
        "    # Cookies æ¥æº\n",
        "    if cookies_path and Path(cookies_path).exists():\n",
        "        print(f\"   Cookies: {cookies_path}\")\n",
        "    else:\n",
        "        print(\"   Cookies: æœªé…ç½®\")\n",
        "\n",
        "\n",
        "# ===== æ ¸å¿ƒåŠŸèƒ½ =====\n",
        "\n",
        "def download_audio(\n",
        "    url: str,\n",
        "    output_dir: Path,\n",
        "    cookies_path: str | None = None,\n",
        "    js_runtimes: dict | None = None\n",
        ") -> tuple[Path, str]:\n",
        "    \"\"\"ä½¿ç”¨ yt-dlp ä¸‹è½½éŸ³é¢‘ï¼Œå°è¯•å¤šç§å®¢æˆ·ç«¯ç»•è¿‡ 403\"\"\"\n",
        "    print(\"ğŸ“¥ æ­£åœ¨ä¸‹è½½éŸ³é¢‘...\")\n",
        "\n",
        "    cookies_opts: dict = {}\n",
        "    if cookies_path and Path(cookies_path).exists():\n",
        "        cookies_opts['cookiefile'] = cookies_path\n",
        "        print(f\"ğŸª ä½¿ç”¨ cookies: {cookies_path}\")\n",
        "\n",
        "    # åŸºç¡€é…ç½®\n",
        "    base_opts = {'quiet': True}\n",
        "    if js_runtimes:\n",
        "        base_opts['js_runtimes'] = js_runtimes\n",
        "    base_opts.update(cookies_opts)\n",
        "\n",
        "    # è·å–è§†é¢‘ä¿¡æ¯\n",
        "    with yt_dlp.YoutubeDL(base_opts) as ydl:\n",
        "        info = ydl.extract_info(url, download=False)\n",
        "        video_title = info.get('title', 'unknown')\n",
        "\n",
        "    safe_title = sanitize_filename(video_title)\n",
        "    output_template = str(output_dir / f\"{safe_title}.%(ext)s\")\n",
        "\n",
        "    # å°è¯•å¤šç§å®¢æˆ·ç«¯é…ç½®æ¥ç»•è¿‡ 403\n",
        "    client_configs = [\n",
        "        {'player_client': ['ios', 'web']},\n",
        "        {'player_client': ['android', 'web']},\n",
        "        {'player_client': ['tv', 'web']},\n",
        "        {},\n",
        "    ]\n",
        "\n",
        "    last_error = None\n",
        "    for extractor_args in client_configs:\n",
        "        client_name = extractor_args.get('player_client', 'default')\n",
        "        print(f\"ğŸ”„ å°è¯•å®¢æˆ·ç«¯: {client_name}\")\n",
        "\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'outtmpl': output_template,\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'mp3',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'quiet': False,\n",
        "            'no_warnings': False,\n",
        "        }\n",
        "        if js_runtimes:\n",
        "            ydl_opts['js_runtimes'] = js_runtimes\n",
        "        ydl_opts.update(cookies_opts)\n",
        "        if extractor_args:\n",
        "            ydl_opts['extractor_args'] = {'youtube': extractor_args}\n",
        "\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                ydl.download([url])\n",
        "\n",
        "            audio_path = output_dir / f\"{safe_title}.mp3\"\n",
        "            if audio_path.exists():\n",
        "                print(f\"âœ… éŸ³é¢‘ä¸‹è½½å®Œæˆ: {audio_path.name}\")\n",
        "                return audio_path, video_title\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "            print(f\"âš ï¸ å®¢æˆ·ç«¯ {client_name} å¤±è´¥: {str(e)[:120]}\")\n",
        "\n",
        "    raise Exception(f\"âŒ æ‰€æœ‰ä¸‹è½½æ–¹å¼éƒ½å¤±è´¥ã€‚æœ€åé”™è¯¯: {last_error}\\n\\n\"\n",
        "                    \"ğŸ’¡ å»ºè®®ï¼šè¯·å¯ç”¨ Cookies åŠŸèƒ½ï¼ˆå‚è€ƒåº•éƒ¨è¯´æ˜ä¸Šä¼  cookies.txtï¼‰\")\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_path: Path, model_name: str, language: str = None) -> dict:\n",
        "    \"\"\"ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘\"\"\"\n",
        "    print(f\"ğŸ”„ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹ ({model_name})...\")\n",
        "    model = whisper.load_model(model_name)\n",
        "\n",
        "    # è·å–éŸ³é¢‘æ—¶é•¿\n",
        "    try:\n",
        "        from whisper.audio import load_audio, SAMPLE_RATE\n",
        "        audio = load_audio(str(audio_path))\n",
        "        audio_duration = len(audio) / SAMPLE_RATE\n",
        "    except Exception:\n",
        "        audio_duration = 0.0\n",
        "\n",
        "    if audio_duration > 0:\n",
        "        print(f\"ğŸµ éŸ³é¢‘æ—¶é•¿: {format_duration(audio_duration)}\")\n",
        "\n",
        "    print(\"ğŸ™ï¸ æ­£åœ¨è½¬å½•éŸ³é¢‘...\")\n",
        "\n",
        "    transcribe_options = {'fp16': True, 'verbose': True}\n",
        "    if language:\n",
        "        transcribe_options['language'] = language\n",
        "\n",
        "    start_time = time.time()\n",
        "    result = model.transcribe(str(audio_path), **transcribe_options)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    detected_lang = result.get('language', 'unknown')\n",
        "    print(f\"\\nâœ… è½¬å½•å®Œæˆï¼æ£€æµ‹åˆ°è¯­è¨€: {detected_lang}\")\n",
        "    print(f\"â±ï¸  å¤„ç†è€—æ—¶: {format_duration(elapsed_time)}\")\n",
        "\n",
        "    if audio_duration > 0:\n",
        "        speed_ratio = audio_duration / elapsed_time\n",
        "        print(f\"ğŸš€ å¤„ç†é€Ÿåº¦: {speed_ratio:.2f}x å®æ—¶é€Ÿåº¦\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def save_outputs(result: dict, output_dir: str, title: str) -> tuple[Path, Path]:\n",
        "    \"\"\"ä¿å­˜ txt å’Œ srt æ–‡ä»¶\"\"\"\n",
        "    safe_title = sanitize_filename(title)\n",
        "    output_path = Path(output_dir)\n",
        "\n",
        "    # ä¿å­˜ txt\n",
        "    txt_file = output_path / f\"{safe_title}.txt\"\n",
        "    with open(txt_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(result['text'].strip())\n",
        "    print(f\"ğŸ“„ æ–‡æœ¬æ–‡ä»¶å·²ä¿å­˜: {txt_file}\")\n",
        "\n",
        "    # ä¿å­˜ srt\n",
        "    srt_file = output_path / f\"{safe_title}.srt\"\n",
        "    segments = result.get('segments', [])\n",
        "    with open(srt_file, 'w', encoding='utf-8') as f:\n",
        "        for i, segment in enumerate(segments, start=1):\n",
        "            start_time = format_timestamp(segment['start'])\n",
        "            end_time = format_timestamp(segment['end'])\n",
        "            text = segment['text'].strip()\n",
        "            f.write(f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
        "    print(f\"ğŸ“„ å­—å¹•æ–‡ä»¶å·²ä¿å­˜: {srt_file}\")\n",
        "\n",
        "    return txt_file, srt_file\n",
        "\n",
        "\n",
        "def process_single_video(\n",
        "    url: str,\n",
        "    output_dir: str,\n",
        "    model: str,\n",
        "    language: str | None,\n",
        "    cookies_path: str | None,\n",
        "    js_runtimes: dict | None\n",
        ") -> bool:\n",
        "    \"\"\"å¤„ç†å•ä¸ªè§†é¢‘ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ\"\"\"\n",
        "    video_id = parse_youtube_url(url)\n",
        "    if not video_id:\n",
        "        print(f\"âŒ æ— æ•ˆçš„ YouTube URL: {url}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"ğŸ¬ Video ID: {video_id}\")\n",
        "\n",
        "    # åˆ›å»ºä¸´æ—¶ç›®å½•\n",
        "    temp_dir = Path(tempfile.mkdtemp())\n",
        "\n",
        "    try:\n",
        "        # ä¸‹è½½éŸ³é¢‘\n",
        "        audio_path, video_title = download_audio(\n",
        "            url,\n",
        "            temp_dir,\n",
        "            cookies_path=cookies_path,\n",
        "            js_runtimes=js_runtimes\n",
        "        )\n",
        "\n",
        "        # è½¬å½•\n",
        "        result = transcribe_audio(audio_path, model, language)\n",
        "\n",
        "        # ä¿å­˜\n",
        "        txt_file, srt_file = save_outputs(result, output_dir, video_title)\n",
        "\n",
        "        print(f\"âœ… å®Œæˆ: {txt_file.name}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å¤„ç†å¤±è´¥: {e}\")\n",
        "        return False\n",
        "\n",
        "    finally:\n",
        "        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
        "        if temp_dir.exists():\n",
        "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
        "\n",
        "\n",
        "def disconnect_runtime():\n",
        "    \"\"\"æ–­å¼€ Colab è¿è¡Œæ—¶ä»¥èŠ‚çœæµé‡\"\"\"\n",
        "    try:\n",
        "        from google.colab import runtime\n",
        "        print(\"ğŸ”Œ 3 ç§’åæ–­å¼€è¿è¡Œæ—¶...\")\n",
        "        time.sleep(3)\n",
        "        runtime.unassign()\n",
        "    except Exception:\n",
        "        # é Colab ç¯å¢ƒåˆ™å¿½ç•¥\n",
        "        pass\n",
        "\n",
        "\n",
        "# ===== ä¸»æ‰§è¡Œæµç¨‹ =====\n",
        "\n",
        "if not url_list:\n",
        "    raise ValueError(\"âŒ æœªæä¾›ä»»ä½• URLï¼Œè¯·åœ¨é…ç½®å•å…ƒæ ¼ä¸­å¡«å†™\")\n",
        "\n",
        "print(f\"ğŸ“‹ æ‰¹é‡ä»»åŠ¡: å…± {len(url_list)} ä¸ªè§†é¢‘\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# æ£€æµ‹ JS runtime\n",
        "js_runtimes = detect_js_runtime()\n",
        "\n",
        "# è®¾ç½® cookies è·¯å¾„\n",
        "cookies_path = COOKIES_PATH if USE_COOKIES else None\n",
        "\n",
        "# ç¯å¢ƒè‡ªæ£€\n",
        "preflight_check(cookies_path, js_runtimes)\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# æ‰¹é‡å¤„ç†\n",
        "success_count = 0\n",
        "fail_count = 0\n",
        "failed_urls = []\n",
        "\n",
        "for idx, url in enumerate(url_list, 1):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"ğŸ“Œ [{idx}/{len(url_list)}] å¤„ç†ä¸­...\")\n",
        "    print(f\"ğŸ”— {url}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    language_opt = LANGUAGE if LANGUAGE else None\n",
        "    success = process_single_video(\n",
        "        url,\n",
        "        OUTPUT_DIR,\n",
        "        MODEL,\n",
        "        language_opt,\n",
        "        cookies_path,\n",
        "        js_runtimes\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        success_count += 1\n",
        "    else:\n",
        "        fail_count += 1\n",
        "        failed_urls.append(url)\n",
        "\n",
        "# æ±‡æ€»æŠ¥å‘Š\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆï¼\")\n",
        "print(f\"   âœ… æˆåŠŸ: {success_count}\")\n",
        "print(f\"   âŒ å¤±è´¥: {fail_count}\")\n",
        "print(f\"ğŸ“ æ–‡ä»¶ä½ç½®: {OUTPUT_DIR}\")\n",
        "\n",
        "if failed_urls:\n",
        "    print(\"\\nâš ï¸ å¤±è´¥çš„ URL:\")\n",
        "    for url in failed_urls:\n",
        "        print(f\"   - {url}\")\n",
        "\n",
        "print(\"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
        "\n",
        "# æ–­å¼€è¿è¡Œæ—¶èŠ‚çœæµé‡\n",
        "disconnect_runtime()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48c558c3",
      "metadata": {
        "id": "48c558c3"
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ“‹ è¯´æ˜\n",
        "\n",
        "### Whisper æ¨¡å‹é€‰æ‹©\n",
        "| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | å‡†ç¡®åº¦ |\n",
        "|------|------|------|--------|\n",
        "| tiny | 39M | æœ€å¿« | è¾ƒä½ |\n",
        "| base | 74M | å¿« | ä¸€èˆ¬ |\n",
        "| small | 244M | ä¸­ç­‰ | è‰¯å¥½ |\n",
        "| medium | 769M | è¾ƒæ…¢ | å¾ˆå¥½ |\n",
        "| large-v3 | 1550M | æ…¢ | æœ€ä½³ |\n",
        "\n",
        "### è¾“å‡ºæ–‡ä»¶\n",
        "- `.txt` - çº¯æ–‡æœ¬è½¬å½•å†…å®¹\n",
        "- `.srt` - å¸¦æ—¶é—´è½´çš„å­—å¹•æ–‡ä»¶ï¼Œå¯å¯¼å…¥è§†é¢‘æ’­æ”¾å™¨\n",
        "\n",
        "### æ–‡ä»¶ä½ç½®\n",
        "è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: `Google Drive/YouTubeTranscripts/`\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ å¸¸è§é—®é¢˜\n",
        "\n",
        "### HTTP 403 Forbidden é”™è¯¯\n",
        "è¿™æ˜¯ YouTube çš„åçˆ¬è™«æœºåˆ¶ï¼Œè§£å†³æ–¹æ³•ï¼š\n",
        "\n",
        "**æ–¹æ³• 1: ä½¿ç”¨ Cookies (æ¨è)**\n",
        "1. å®‰è£…æµè§ˆå™¨æ‰©å±• [Get cookies.txt LOCALLY](https://chromewebstore.google.com/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc)\n",
        "2. ç™»å½• YouTube è´¦å·\n",
        "3. åœ¨ YouTube é¡µé¢ç‚¹å‡»æ‰©å±•ï¼Œå¯¼å‡º cookies.txt\n",
        "4. ä¸Šä¼ åˆ° Google Drive æ ¹ç›®å½• (MyDrive/cookies.txt)\n",
        "5. åœ¨é…ç½®ä¸­è®¾ç½® `USE_COOKIES = True`\n",
        "\n",
        "**æ–¹æ³• 2: ç­‰å¾… yt-dlp æ›´æ–°**\n",
        "- yt-dlp ä¼šå®šæœŸæ›´æ–°ä»¥é€‚åº” YouTube å˜åŒ–\n",
        "- é‡æ–°è¿è¡Œã€Œå®‰è£…ä¾èµ–ã€å•å…ƒæ ¼ä¼šè‡ªåŠ¨æ›´æ–°åˆ°æœ€æ–°ç‰ˆ\n",
        "\n",
        "### è§†é¢‘æ— æ³•ä¸‹è½½\n",
        "ä»¥ä¸‹è§†é¢‘å¯èƒ½æ— æ³•ä¸‹è½½ï¼š\n",
        "- ç§äº«è§†é¢‘ (Private)\n",
        "- å¹´é¾„é™åˆ¶è§†é¢‘ (éœ€ç™»å½• + Cookies)\n",
        "- åœ°åŒºé™åˆ¶è§†é¢‘\n",
        "- ä»˜è´¹/ä¼šå‘˜ä¸“äº«å†…å®¹"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
